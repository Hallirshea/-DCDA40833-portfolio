<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Skills Portfolio showcasing work from DCDA 40833">
    <meta name="author" content="Halli Shea">
    <title>Lab 02: AI Tool Evaluation</title>
    <link rel="stylesheet" href="css/styles.css">
</head>
<body>


    <!-- Navigation: Links to all portfolio pages -->
    <nav>
        <ul>
            <li><a href="index.html">Home</a></li>
            <li><a href="ai-evaluation.html">AI Evaluation</a></li>
            <li><a href="tufte-critique.html">Tufte Critique</a></li>
            <li><a href="tableau-visualization.html">Tableau Viz</a></li>
            <li><a href="lab5.html">Lab 5</a></li>
            <li><a href="hometown-map.html">Hometown Map</a></li>
        </ul>
    </nav>
<header>
  <h1>Lab 02: AI Tool Evaluation</h1>
</header>
<main>
  <section>
    <h2>Evidence: AI Tool Testing</h2>
    <p>This section documents screenshots and examples from testing ChatGPT and Claude.</p>
  <h3>Claude: Brainstorming Captions</h3>
    <img
  src="images/lab02/chatgpt/claude/claude-brainstorm.png"
  alt="Claude brainstorming Instagram captions for $3 margaritas"
>
<p>
  Claude’s captions felt more playful and conversational, but some ideas were longer and slightly less filtered.
</p>

<h3>ChatGPT: Brainstorming Captions</h3>
<img
  src="images/lab02/chatgpt/chatgpt-brainstorm.png"
  alt="ChatGPT brainstorming Instagram captions for $3 margaritas"
>
<p>
  ChatGPT’s captions were cleaner and more concise, but felt safer and less creative overall.
</p>
<section>
  <h2>Tone Testing: Casual College-Student Writing</h2>

  <p>
    This test focused on how well each AI tool could rewrite a formal portfolio paragraph into a more natural, casual college-student tone.
  </p>

  <h3>Claude: Tone Rewrite</h3>
  <img
    class="lab-image"
    src="images/lab02/chatgpt/claude/claude-tone.png"
    alt="Claude rewriting a portfolio paragraph in a casual tone"
  >

  <img
    class="lab-image"
    src="images/lab02/chatgpt/claude/claude-tone2.png"
    alt="Second Claude example of casual tone rewrite"
  >

  <p>
    Claude’s rewrite felt conversational and personable, but leaned longer and more informal than necessary for a portfolio context.
  </p>

  <h3>ChatGPT: Tone Rewrite</h3>
  <img
    class="lab-image"
    src="images/lab02/chatgpt/chatgpt-tone.png"
    alt="ChatGPT rewriting a portfolio paragraph in a casual tone"
  >

  <img
    class="lab-image"
    src="images/lab02/chatgpt/chatgpt-tone2.png"
    alt="Second ChatGPT example of casual tone rewrite"
  >

  <p>
    ChatGPT’s rewrite was clearer and more structured, but felt slightly safer and less expressive overall.
  </p>
</section>


  </section>

<section>
  <h2>Fact-Checking Test: 1970s TV News + Citations</h2>
  <p>
    I asked both ChatGPT and Claude a factual question about 1970s news consumption and then followed up by asking for sources/citations.
    This helped me see how each tool handles uncertainty and credibility.
  </p>

  <h3>Claude: Answer + Citation Follow-Up</h3>
  <img
    src="images/lab02/chatgpt/claude/claude-facts.png"
    alt="Claude answer about 1970s news consumption"
  >
  <img
    src="images/lab02/chatgpt/claude/claude-facts2.png"
    alt="Claude follow-up response about citations for 1970s news consumption"
  >
  <p>
    Claude provided confident-sounding context, but when I asked for citations it stayed broad and didn’t give exact URLs, which makes it hard to verify.
  </p>

  <h3>ChatGPT: Answer + Citation Follow-Up</h3>
  <img
    src="images/lab02/chatgpt/chatgpt-facts.png"
    alt="ChatGPT answer about 1970s news consumption"
  >
  <img
    src="images/lab02/chatgpt/chatgpt-facts2.png"
    alt="ChatGPT follow-up response about citations for 1970s news consumption"
  >
  <p>
    ChatGPT was more cautious about claiming a single exact number and emphasized limits, but it still requires outside verification before using any stats in a paper.
  </p>
</section>
<section>
  <h2>Reflection & Analysis</h2>

  <p>
    For this lab, I tested two AI tools, ChatGPT and Claude, to better understand what they are good at, where they struggle, and how they could be used responsibly in academic and professional settings. I used both tools for tasks related to strategic communication, including brainstorming Instagram captions, rewriting a portfolio paragraph in a casual college-student tone, and answering a factual question about news consumption in the 1970s. Testing both tools side by side helped highlight their differences more clearly.
  </p>

  <p>
    Both ChatGPT and Claude worked well for brainstorming ideas. When asked to create Instagram captions for $3 margaritas, both tools produced relevant and usable options. Claude’s captions felt more playful and expressive, sometimes leaning into humor or longer phrasing. ChatGPT’s captions were more concise and structured, which made them easier to use without much editing. This showed that the quality of AI output depends heavily on the prompt and the type of tone the user is looking for.
  </p>

  <p>
    The tone rewrite task showed a noticeable difference between the two tools. Claude rewrote the paragraph in a very conversational way, but the response ended up being longer and more informal than what would likely be used on a portfolio website. ChatGPT’s version felt more balanced and organized, keeping a casual tone while still sounding clear and professional. This suggests that ChatGPT may be better for polished writing, while Claude is more useful for early drafts or experimenting with voice.
  </p>

  <p>
    Both tools struggled when it came to factual accuracy and citations. When asked about the percentage of Americans who got their news from ABC, CBS, or NBC in the 1970s, neither tool could provide a single exact number with clear sources. ChatGPT was more open about uncertainty and explained why exact data is difficult to determine, while Claude gave general historical context without direct citations. This reinforced that AI tools should not be relied on for factual information without outside verification.
  </p>

  <p>
    Overall, this lab showed that AI tools are most useful as support tools rather than replacements for human thinking. They are helpful for brainstorming, rewriting drafts, and exploring tone, but they should not be used as final authorities for facts or academic claims. In the context of the DCDA program, AI tools can enhance creativity and efficiency, but skills like critical thinking, ethical judgment, and interpretation remain uniquely human and essential.
  </p>
</section>

<section>
  <h2>AI Use Disclosure</h2>
  <p>
    ChatGPT and Claude were used to explore brainstorming, tone rewriting, and factual responses. All analysis, interpretation, and final writing decisions were made by the author.
  </p>
</section>

</main>

</body>
